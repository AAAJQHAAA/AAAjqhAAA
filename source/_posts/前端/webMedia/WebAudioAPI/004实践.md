# Web音频API最佳实践
- 在编写创造性的代码时，没有严格的正确或错误的方法。只要考虑到安全性、性能和可访问性，您就可以适应自己的风格。在本文中，我们将分享一些最佳实践-使用Web Audio API的指导方针、提示和技巧。
# 加载声音/文件
- 使用Web Audio API加载声音的方法主要有四种，对于应该使用哪一种可能会有点混乱。
- 在处理文件时，您可以从HTMLMediaElement（即<audio>或<video>元素）中抓取文件，或者获取文件并将其解码到缓冲区中。两者都是合法的工作方式，但是，当您处理全长轨道时，更常见的是使用前者，而当处理较短，更像样本的轨道时，使用后者。
  - 长的使用标签
  - 短的使用缓冲区
  - 媒体元素具有开箱即用的流媒体支持。当浏览器确定可以在播放结束前加载文件的其余部分时，音频将开始播放。您可以在使用Web音频API教程中查看如何将其与Web音频API一起使用的示例。
  - 但是，如果使用缓冲节点，您将拥有更多的控制权。您必须请求文件并等待它加载（我们的高级文章的这一部分展示了一种很好的方法），但之后您可以直接访问数据，这意味着更精确，更精确的操作。
- 如果您希望使用来自用户摄像头或麦克风的音频，则可以通过[媒体捕获和流API](https://developer.mozilla.org/en-US/docs/Web/API/Media_Capture_and_Streams_API)以及MediaStreamAudioSourceNode接口访问它。这对于WebRTC以及您可能想要记录或分析音频的情况很好。
- 最后一种方法是生成您自己的声音，可以使用OscillatorNode或通过创建缓冲区并使用您自己的数据填充它来完成。查看这里的教程[创建自己的乐器](https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API/Advanced_techniques)，了解如何使用振荡器和缓冲器创建声音。
# 跨浏览器和传统支持
- Web Audio API规范在不断发展，就像Web上的大多数东西一样，它在跨浏览器一致工作时存在一些问题。在这里，我们将看看解决跨浏览器问题的选项。
- 有[standardized-audio-context](https://github.com/chrisguttandin/standardized-audio-context)的npm包，它在浏览器之间创建一致的API功能，填补发现的漏洞。它一直在开发中，并努力跟上当前的规范。
- 还有一个库选项，其中有几个取决于您的用例。对于一个优秀的多面手来说，[howler.js](https://howlerjs.com/)是一个不错的选择。它具有跨浏览器支持，并提供了有用的功能子集。虽然它没有利用Web Audio API附带的全部过滤器和其他效果，但您可以完成大多数您想要做的事情。
- 如果您正在寻找声音创建或更多基于乐器的选项，[tone.js](https://tonejs.github.io/)是一个很好的库。它提供了高级的调度功能、合成器和效果，以及基于Web Audio API的直观音乐抽象。
- [R-audio](https://github.com/bbc/r-audio)来自BBC的研发部门，是一个React组件库，旨在为Web Audio提供“更直观、更声明的接口”。如果您习惯于编写JSX，可能值得一看。
# 自动播放策略
- 浏览器已经开始实施自动播放策略，一般可以总结为
  - 从用户手势内部创建或恢复上下文
- 但这在实践中意味着什么呢？用户手势被解释为表示用户发起的事件，通常是click事件。浏览器供应商决定不允许Web音频上下文自动播放音频;它们应该由用户启动。这是因为自动播放音频可能真的很烦人和突兀。但我们该怎么处理？
- 当您创建音频上下文（离线或在线）时，它是用state创建的，可以是suspended、running或closed
- 使用AudioContext时，如果您从click事件内部创建音频上下文，则状态应自动设置为running。下面是一个从click事件内部创建上下文的简单示例：
```jsavscript
const button = document.querySelector("button");
button.addEventListener(
  "click",
  () => {
    const audioCtx = new AudioContext();
    // Do something with the audio context
  },
  false,
);
```
- 但是，如果您在用户手势之外创建上下文，则其状态将设置为suspended，并且需要在用户交互后启动。我们可以在这里使用相同的click事件示例，测试上下文的状态并启动它，如果它被挂起，使用resume()方法
```jsavscript
const audioCtx = new AudioContext();
const button = document.querySelector("button");

button.addEventListener(
  "click",
  () => {
    // check if context is in suspended state (autoplay policy)
    if (audioCtx.state === "suspended") {
      audioCtx.resume();
    }
  },
  false,
);
```
- 您可能正在使用OfflineAudioContext，在这种情况下，您可以使用startRendering()方法恢复暂停的音频上下文
# 用户控制
- 如果你的网站或应用程序包含声音，你应该允许用户控制它，否则它会变得烦人。这可以通过播放/停止和音量/静音控制来实现。使用Web音频API教程介绍了如何做到这一点
- 如果您有用于打开和关闭音频的按钮，那么在这些按钮上使用ARIArole="switch"属性是一个很好的选择，可以向辅助技术发送该按钮的确切用途，从而使应用更易于访问。这里有一个[演示如何使用它](https://codepen.io/Wilto/pen/ZoGoQm?editors=1100)
- 当您在Web Audio API中处理大量不断变化的值时，并希望为用户提供对这些值的控制，range input通常是一个很好的控件选择。这是一个很好的选择，因为您可以设置最小值和最大值，以及使用step属性的增量
# 设置AudioParam值
- 有两种方法可以操作AudioNode值，它们本身就是AudioParam接口类型的对象。第一种是直接通过属性设置值。例如，如果我们想改变gain的GainNode值，我们可以这样做：
  - `gainNode.gain.value = 0.5;`
- 这将使我们的音量减半。但是，如果您使用AudioParam定义的任何方法来设置这些值，它们将优先于上述属性设置。例如，如果你想在2秒内将gain值提升到1，你可以这样做：
  - `gainNode.gain.setValueAtTime(1, audioCtx.currentTime + 2);`
  - 它将覆盖前面的示例（应该如此），即使它将在代码的后面出现。
- 记住这一点，如果你的网站或应用程序需要定时和调度，最好坚持使用AudioParam方法来设置值。如果你确定它没有，用value属性来设置它也可以。
